# Labs for I2DS


## Module  1: 

### DataCrunchers  story: 
	- Hi, my name is “Amber”.  Welcome to DataCrunchers, we’re so glad that you accepted our internship position.  You’ll find this opportunity fast-paced and exciting – you’ll get to work with all types of businesses and organizations to help them solve problems.  Our team is working on some challenging projects right now, so let’s get you started. 

	In topic 1.1.4. "The data analysts at DataCrunchers work hard to create stories and reports from their clients’ data.  To make the information relevant and actionable by the client management and staff, the analysts rely heavily on visualization techniques. "  

	
## Lab 1:
 - Ice Cream Shop Lab 
"One of our clients  at DataCrunchers is "Flavors", an ice cream shop. They want to know the most popular ice cream flavors to help them manage their inventory. 






## Module  2: Data Collection / Storage
- TLO		Identify the primary components of data collection and storage 
 We're not quite sure where we're going to go with yet, but it'll be something around game data and game data sources and what you would do with different data sources. 

 Module 2 Text about DataCrunchers: 

 Defining Big Data (2.1.1) 
You have learned a lot about data types and visualizations from the data analysts at DataCrunchers. Now it is time to work alongside one of the company data engineers to learn about big data and their role in building, maintaining, and ensuring a production-ready big data environment.  

Big data is a term used to describe massive volumes of data. A data set or a business problem classifies as Big Data when its data is so vast, fast, or complex that it becomes impossible to store, process, and analyze using traditional data storage and analytics applications.  



## Lab 2:

Hi I'm Taylor and I'm a data engineer. Did you ever think about how your music app company manages to collect your data and return Music you want to hear for you to listen to? Data is being generated all the time everywhere e.g., mobile phones, websites, iot devices. Data engineers build the infrastructure and pipelines to ingest the data from all these sources, process it by cleaning, augmenting, and transforming it in ways that support data scientists' analyses, and land it in the appropriate places to support the business- databases, object storage, or Hadoop.    I help people solve problems aroung getting their data in the right location and shape so that they can run cool predictive models and answer business questions.

Data engineers work in a variety of settings to build systems that collect, manage, and convert raw data into usable information for data scientists and business analysts to interpret. Their ultimate goal is to make data accessible so that organizations can use it to evaluate and optimize their performance

DataCrunchers does some pro bono work too, so I'm working on a project with these folks:

- The Ant Game Launch Video: https://www.youtube.com/watch?v=MGJxqdYr2Bo

Website: https://gettheantgame.com/ 

They've created a cool game to teach kids about complex systems. It is available it on the app and play stores. The big issue they want our help with is improving retention. Their research shows people learn more the more they play the game, so they want to understand the factors that impact retention so they can create models to predict it. 

They built the game in unity, so they know there is a way to be able to tap into the player data coming from their game. They don't have the money to hire their own data engineer. So first we built them a pipeline for their data. Now that we've built them a data pipeline, they can capture events like a player starting and stopping playing with the tutorial. 

Their exploratory data analysis shows that the amount of time that players play with the tutorial is a good predictor of retention. The data are logged as json events that look like this. They need to transform these events into nice looking tables like these.
 


- animation of an  "event" travelling from a mobile phone to a server, message ...(?)
- Show a simple basic "event" json, point out the data we're looking for
- activity in "spark" to pull out the timing data & transform it from lump to monthly average usage or something.
- animation of the transformed data landing in S3, GCP,(?)

## Module 3: 

VIDEO - Popular Concepts of Artificial Intelligence (3.1.1)  

 

Script:  At  DataCrunchers, there are a few projects  that are garnering a lot of attention  from both  our employees  and clients. These projects are among our first that involve  artificial intelligence, robots, and machine learning – yes, that stuff that used to be only in science fiction movies. One project that we are working on involves  gathering data from images and GPS information to train a robot to use AI-enabled  cameras to differentiate between weeds and crops in order to reduce the use of chemical herbicides. That may not  sound  like a big project, but it requires a significant amount of unstructured data in the form of images and video that must be analyzed throughout the machine learning process. Complex algorithms enable the recognition to occur with great accuracy and speed. 

## Lab 3:

AIML:  a simple vision training tool: 
	- 1. show something to the camera and take a picture  
	- 2. label it  
	- 3. generate a training data set  
	- 4. Click train my model - trains it (but montage version because usually training takes a long time.)
	- 5. test it: teach them how to build a test set or they can just test it live? 
	- 6. an activity around learners comparing their training and test data to see how their model performed, and whether they need to do some adjustment to it.





## Module 4	Embarking on Your Career in Data Anlytics
	- TLO Discover the different job roles in Data Analytics

## Lab 4:

	- OK now it's time for you to look at what kind of jobs you might get to do"?
	- we will use actual job data to generate some data which matches that shape and distribution(Patti has it)
	- learners will do some simple exploration in the job data using a similar tool to Lab 1, but with the job data, 




###Number and timing of labs for data0

- Each of these labs would take a newbie half an hour, as an estimate. 
- two hours of the course total. 
- Planning for one lab per module