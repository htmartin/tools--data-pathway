Critical Work Functions Key Tasks Singapore SF Data Engineer
https://cloud.google.com/certification/guides/data-engineer

The Data Engineer supports the design, implementation and
maintenance of data flow channels and data processing systems
that support the collection, storage, batch and real-time
processing, and analysis of information in a scalable, repeatable
and secure manner. He/She focuses on defining optimal
solutions to data collection, processing and warehousing. He
designs, codes and tests data systems and works on
implementing those into the internal infrastructure. He focuses
on collecting, parsing, managing, analysing and visualising large
sets of data to turn information into insights accessible through
multiple platforms.
He is proficient in database systems, scripting and programming
languages required by the organisation. He is also familiar with
the relevant software platforms on which the solution is
deployed on.
The Data Engineer is passionate about numbers and works with
large data sets. He has a keenness for understanding business
processes and resolving challenges in order to provide solutions
with the help of clean and interlinked databases and architectures.

## Identify business needs

	• Identify suitable data structures based on business needs to ensure availability and accessibility of data
		- Data Types 
			- Abstract
			- Composite 
			- Primitive
		- Data structures
			- Types
				- Array 
				- Stack 
				- Queue 
				- Linked List 
			- Characteristics 
				- Linear and Nonlinear.
				- Static and Dynamic.
				- Homogenous and Non-Homogenous.
		- Relate all of that to 
			- data availability
				- timeliness  
				- reliability
				- accessibility
		- decision processes
			-  models  
			- Use case studies to walk through decision examples

	• Determine technical system requirements based on data needs
	• Keep abreast of latest technologies and products in database and data processing software, and technologies


## Build and maintain data pipelines

	• Assist in building scalable data pipelines to extract, transform, load and integrate data
		- What is a data pipeline
	• Develop codes and scripts to process structured and unstructured data in real-time from a variety of data sources
		- structured data  
		- unstructured data
		- latency
		- ways to work with structured data
		- ways to work with unstructured data
		- creating reuseable ways to process data
			- coding and scripting
			- testing


	• Test data pipelines for scalability and reliability to process high data volume, variety and velocity
	• Consolidate and create data storage solutions for storage and retrieval of information
	• Develop prototypes and proof-of-concepts for data solutions
	• Monitor data system performance
	• Support the handling and logging of errors
	• Develop backup data archiving systems to ensure system continuity
	• Implement and monitor data security and privacy measures on existing data solutions


## Optimise solution performance
	• Assist in the integration of data systems with existing infrastructure
	• Develop tools to improve data flows between internal and/or external systems and the data warehouse
	• Automate the data collection and analysis processes, data releasing and reporting tools
	• Test data system configurations to increase efficiency
